{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chinese_dataset = 'article_9k.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(chinese_dataset,'r') as f:\n",
    "    CHINESE_CHARATES = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'此外自本周6月12日起除小米手机6等15款机型外其余机型已暂停更新发布含开发版体'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHINESE_CHARATES[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pinyin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chinese_to_pinyin(character):\n",
    "    return pinyin.get(character,format='strip',delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHINESE_CHARATES_COPYS = chinese_to_pinyin(CHINESE_CHARATES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129433034"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CHINESE_CHARATES_COPYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(CHINESE_CHARATES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokens(text):\n",
    "    return re.findall('[a-z]+',text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter,defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PINYIN_COUNT = Counter(tokens(CHINESE_CHARATES_COPYS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PINYIN_ALL = tokens(CHINESE_CHARATES_COPYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct(word):\n",
    "    candidates = (known(edits0(word)) or\n",
    "                  known(edits1(word)) or\n",
    "                  known(edits2(word)) or\n",
    "                  [word])\n",
    "    return max(candidates,key=PINYIN_COUNT.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def known(words):\n",
    "    return {w for w in words if w in PINYIN_COUNT}\n",
    "\n",
    "def edits0(word):\n",
    "    return {word}\n",
    "\n",
    "def edits2(word):\n",
    "    return { e2 for e1 in edits1(word) for e2 in edits1(e1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splits(word):\n",
    "    return [(word[:i],word[i:])\n",
    "            for i in range(len(word)+1)]\n",
    "def edits1(word):\n",
    "    pairs = splits(word)\n",
    "    deletes = [a+b[1:] for (a,b) in pairs if b]\n",
    "    transposes = [a+b[1]+b[0]+b[2:] for (a,b) in pairs if len(b) > 1]\n",
    "    replaces = [a+c+b[1:] for (a,b) in pairs for c in alphabet if b]\n",
    "    inserts = [a+c+b for (a,b) in pairs for c in alphabet]\n",
    "    return set(deletes + transposes + replaces + inserts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct_sequence_pinyin(text_pinyin):\n",
    "    return ' '.join(map(correct, text_pinyin.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wo xiang shang qing hua da xue'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_sequence_pinyin('wo xiang shagn qinng hua da xue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ci', 'wai', 'zi', 'ben', 'zhou', 'yue', 'ri', 'qi', 'chu', 'xiao']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PINYIN_ALL[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shi', 860634),\n",
       " ('de', 809887),\n",
       " ('n', 691114),\n",
       " ('yi', 682478),\n",
       " ('ji', 645276),\n",
       " ('guo', 430042),\n",
       " ('zhong', 409418),\n",
       " ('zhi', 398612),\n",
       " ('xin', 359619),\n",
       " ('li', 355441)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PINYIN_COUNT.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_1(word):\n",
    "    return PINYIN_COUNT[word] / len_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_PINYIN_ALL = len(PINYIN_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PINYIN_ALL_2 = [''.join(PINYIN_ALL[i:i+2]) for i in range(len_PINYIN_ALL-2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PINYIN_ALL_3 = [''.join(PINYIN_ALL[i:i+3]) for i in range(len_PINYIN_ALL-3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PINYIN_COUNT_2 = Counter(PINYIN_ALL_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PINYIN_COUNT_3 = Counter(PINYIN_ALL_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_PINYIN_ALL_2 = len(PINYIN_ALL_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_PINYIN_ALL_3 = len(PINYIN_ALL_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_2(word1,word2):\n",
    "    if word1 + word2 in PINYIN_COUNT_2: return PINYIN_COUNT_2[word1+word2] / PINYIN_COUNT[word2]\n",
    "    else: return 1/len_PINYIN_ALL_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_3(word1,word2,word3):\n",
    "    if word1 + word2 + word3 in PINYIN_COUNT_3: return PINYIN_COUNT_3[word1+word2+word3] / PINYIN_COUNT_2[word2+word3]\n",
    "    else: return 1/len_PINYIN_ALL_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_probablity_2_gram(words):\n",
    "    \n",
    "    sentence_pro = 1\n",
    "    \n",
    "    for i, word in enumerate(words[:-1]):\n",
    "        next_1 = words[i+1]\n",
    "        \n",
    "        probability = prob_2(word, next_1)\n",
    "        \n",
    "        sentence_pro *= probability\n",
    "    sentence_pro = probability * (PINYIN_COUNT[next_1] / len_PINYIN_ALL_2)\n",
    "    return sentence_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_probablity_3_gram(words):\n",
    "    \n",
    "    sentence_pro = 1\n",
    "    \n",
    "    for i, word in enumerate(words[:-2]):\n",
    "        next_1 = words[i+1]\n",
    "        next_2 = words[i+2]\n",
    "        \n",
    "        probability = prob_3(word, next_1, next_2)\n",
    "        \n",
    "        sentence_pro *= probability\n",
    "    sentence_pro = probability * (PINYIN_COUNT_2[next_1+next_2] / len_PINYIN_ALL_3)\n",
    "    return sentence_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yuanyin = ['a','i','e','o','u','v']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#元音位置的list\n",
    "def find_yuanyin_position(string):\n",
    "    yuanyin_position = []\n",
    "    for i in yuanyin:\n",
    "        i_list = [j.start() for j in re.finditer(str(i), string)]\n",
    "        yuanyin_position = yuanyin_position + i_list\n",
    "        yuanyin_position = sorted(yuanyin_position)\n",
    "    return yuanyin_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#把一个完整的拼音切出来\n",
    "def cut_pinyin(string):\n",
    "    #所有元音的位置\n",
    "    yuanyin_position = find_yuanyin_position(string)\n",
    "    #找到第一个元音的位置\n",
    "    min_position = yuanyin_position[0]\n",
    "    #如果只有一个拼音且只有一个元音\n",
    "    if len(yuanyin_position) == 1:\n",
    "        return string\n",
    "    #如果只有一个拼音且有两个元音\n",
    "    elif len(yuanyin_position) == 2 and (yuanyin_position[0] + 1 == yuanyin_position[1]):\n",
    "        return string\n",
    "    elif len(yuanyin_position) == 3 and (yuanyin_position[0] + 1 == yuanyin_position[1]) and (yuanyin_position[0] + 2 == yuanyin_position[2]):\n",
    "        return string\n",
    "    else:\n",
    "        #如果第一个拼音有一个元音\n",
    "        if (min_position + 1) not in yuanyin_position:\n",
    "            #找到第三个元音也是第二个拼音的元音\n",
    "            second_pinyin_yuanyin = yuanyin_position[1]\n",
    "            if string[second_pinyin_yuanyin-2] in ['z','c','s']:\n",
    "                return string[:second_pinyin_yuanyin-2]\n",
    "            else:return string[:second_pinyin_yuanyin-1]\n",
    "        #如果第一个拼音有两个元音且第二个拼音不仅仅是一个字母\n",
    "        elif (min_position + 1) in yuanyin_position and (min_position + 2) not in yuanyin_position:\n",
    "            #找到第三个元音也是第二个拼音的元音\n",
    "            second_pinyin_yuanyin = yuanyin_position[2]\n",
    "            #判断第二个拼音前面有几个辅音属于第二个拼音\n",
    "            if string[second_pinyin_yuanyin-2] in ['z','c','s']:\n",
    "                return string[:second_pinyin_yuanyin-2]\n",
    "            else:return string[:second_pinyin_yuanyin-1]\n",
    "        #如果第一个拼音有两个元音且第二个拼音仅仅是一个字母\n",
    "#         elif (min_position + 1) in yuanyin_position and (min_position + 2) in yuanyin_position:\n",
    "#             second_pinyin_yuanyin = yuanyin_position[2]\n",
    "#             return string[:second_pinyin_yuanyin]\n",
    "        #如果第一个拼音有三个元音\n",
    "        elif (min_position + 1) in yuanyin_position and (min_position + 2) in yuanyin_position:\n",
    "            second_pinyin_yuanyin = yuanyin_position[2]\n",
    "            return string[:second_pinyin_yuanyin+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把这个完整的拼音切分成多种可能性 如：zhuang: zhu zhuang\n",
    "def cut_one_pinyin(one_pinyin):\n",
    "    #每个拼音的可能性\n",
    "    all_pinyin = []\n",
    "    if (one_pinyin[-1] in ['i','u','v']) or (len(find_yuanyin_position(one_pinyin)) == 1):\n",
    "        list1 = []\n",
    "        list1.append(one_pinyin)\n",
    "        all_pinyin.append(list1)\n",
    "        return all_pinyin\n",
    "\n",
    "    elif len(find_yuanyin_position(one_pinyin)) == 2:\n",
    "        #这里是zhuang的第一个元音位置\n",
    "        first_yuanyin_position = find_yuanyin_position(one_pinyin)[0]\n",
    "        #找出两个可能\n",
    "        list1 = []\n",
    "        list2 = []\n",
    "        list1.append(one_pinyin[:first_yuanyin_position+1])\n",
    "        list1.append(one_pinyin[first_yuanyin_position+1:])\n",
    "        list2.append(one_pinyin)\n",
    "        all_pinyin.append(list1)\n",
    "        all_pinyin.append(list2)\n",
    "        return all_pinyin\n",
    "    elif len(find_yuanyin_position(one_pinyin)) == 3:\n",
    "        #这里是shuai的第一个元音位置\n",
    "        first_yuanyin_position = find_yuanyin_position(one_pinyin)[0]\n",
    "        #找出四个可能\n",
    "        list1 = []\n",
    "        list2 = []\n",
    "        list3 = []\n",
    "        list4 = []\n",
    "        list1.append(one_pinyin[:first_yuanyin_position+1])\n",
    "        list1.append(one_pinyin[first_yuanyin_position+1:])\n",
    "        list2.append(one_pinyin[:first_yuanyin_position+2])\n",
    "        list2.append(one_pinyin[first_yuanyin_position+2:])\n",
    "        list3.append(one_pinyin[:first_yuanyin_position+1])\n",
    "        list3.append(one_pinyin[first_yuanyin_position+1])\n",
    "        list3.append(one_pinyin[first_yuanyin_position+2])\n",
    "        list4.append(one_pinyin)\n",
    "        all_pinyin.append(list1)\n",
    "        all_pinyin.append(list2)\n",
    "        all_pinyin.append(list3)\n",
    "        all_pinyin.append(list4)\n",
    "        return all_pinyin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#将一句话分割成拼音段\n",
    "def all_pinyin_list(string):\n",
    "    len_string = len(cut_pinyin(string))\n",
    "    if len(string[len_string:]) > 0:\n",
    "        return cut_pinyin(string) + ' ' +  all_pinyin_list(string[len_string:])\n",
    "    else:\n",
    "        return cut_pinyin(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#找到一句话所有拼音的可能性\n",
    "def find_pinyin_pro(string):\n",
    "    pinyin_list = all_pinyin_list(string).split(' ')\n",
    "    all_pro_list = []\n",
    "    for i in pinyin_list:\n",
    "        a = cut_one_pinyin(i)\n",
    "        all_pro_list.append(a)\n",
    "    return all_pro_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 对一个拼音的所有可能性纠错\n",
    "def jiucuo_list(pinyin_list):\n",
    "    for i in range(len(pinyin_list)):\n",
    "        for j in range(len(pinyin_list[i])):\n",
    "            pinyin_list[i][j] = correct(pinyin_list[i][j])\n",
    "    return pinyin_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#找到每句话的可能性并进行纠错\n",
    "def find_sen_pro(string):\n",
    "    all_pro_list = find_pinyin_pro(string)\n",
    "    for k in range(len(all_pro_list)-1):\n",
    "        #放所有的可能性\n",
    "        pro_list = all_pro_list[0]\n",
    "        for i in range(len(pro_list[0])):\n",
    "            pro_list[0][i] = correct(pro_list[0][i])\n",
    "       #取出下一个拼音的所有可能性\n",
    "        next_list = all_pro_list[k+1]\n",
    "        next_list = jiucuo_list(next_list)\n",
    "        if len(next_list) == 1:\n",
    "            for i in range(len(pro_list)):\n",
    "                pro_list[i] = pro_list[i] + next_list[0]\n",
    "        elif len(next_list) == 2:\n",
    "            pro_list_1 = copy.deepcopy(pro_list)\n",
    "            pro_list_2 = copy.deepcopy(pro_list)\n",
    "            for i in range(len(pro_list_1)):\n",
    "                pro_list_1[i] = pro_list_1[i] + next_list[0]\n",
    "            for i in range(len(pro_list_2)):\n",
    "                pro_list_2[i] = pro_list_2[i] + next_list[1]\n",
    "            pro_list = pro_list_1 + pro_list_2\n",
    "        elif len(next_list) == 4:\n",
    "            pro_list_1 = copy.deepcopy(pro_list)\n",
    "            pro_list_2 = copy.deepcopy(pro_list)\n",
    "            pro_list_3 = copy.deepcopy(pro_list)\n",
    "            pro_list_4 = copy.deepcopy(pro_list)\n",
    "            for i in range(len(pro_list_1)):\n",
    "                pro_list_1[i] = pro_list_1[i] + next_list[0]\n",
    "            for i in range(len(pro_list_2)):\n",
    "                pro_list_2[i] = pro_list_2[i] + next_list[1]\n",
    "            for i in range(len(pro_list_3)):\n",
    "                pro_list_3[i] = pro_list_3[i] + next_list[2]\n",
    "            for i in range(len(pro_list_4)):\n",
    "                pro_list_4[i] = pro_list_4[i] + next_list[3]\n",
    "            pro_list = pro_list_1 + pro_list_2 + pro_list_3 + pro_list_4\n",
    "        all_pro_list[0] = pro_list\n",
    "    return all_pro_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pro_sen(string):\n",
    "    all_pro_sen_list = find_sen_pro(string)\n",
    "#     print(all_pro_sen_list)\n",
    "    #放每个句子概率的列表\n",
    "    all_pro_num_list = []\n",
    "    min_len = 1000\n",
    "    for sen in all_pro_sen_list:\n",
    "        if len(sen) < min_len:\n",
    "            min_len = len(sen)\n",
    "    all_sen_pro = []\n",
    "    for sen in all_pro_sen_list:\n",
    "        sen_pro = get_probablity_3_gram(sen[:min_len])\n",
    "        all_sen_pro.append(sen_pro)\n",
    "#     print(all_sen_pro)\n",
    "#     print(all_sen_pro.index(max(all_sen_pro)))\n",
    "    return all_pro_sen_list[all_sen_pro.index(max(all_sen_pro))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "string = 'woxiangshangqinnghuadaxue'#qinng -> qing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wo', 'xiang', 'shang', 'qing', 'hua', 'da', 'xue']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pro_sen(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "string = 'xianweiyuzhongguoxinan'#西安位于中国西南 xian -> xi an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xi', 'an', 'wei', 'yu', 'zhong', 'guo', 'xi', 'nan']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pro_sen(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "string = 'xiannvhaopiaoliang'#仙女好漂亮 xian -> xian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xian', 'nv', 'hao', 'piao', 'liang']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pro_sen(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "string = 'woxiangshagnqinnghua'# shagn -> shang  qinng ->qing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wo', 'xiang', 'shang', 'qing', 'hua']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pro_sen(string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
